{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following the idea of [Ahmed Besbes](http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html) with my own implementation\n",
    "\n",
    "I tried to implement some of his feature engineering steps in titanic_tutorial, but it became too messy. Here is a new start from scratch.\n",
    "\n",
    "### Purpose\n",
    "* Reproduce his result\n",
    "* Find out the key to better result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* Data exploration\n",
    "  * Using violine plot, one could check if some features are more important.\n",
    "  * For Titanic data set, the most important ones are gender and age. Using gender alone can reach about 75% accuracy.\n",
    "* Data engineering tricks\n",
    "  * Need to provide missing values.\n",
    "  * If possible, should combine test features and target features to make the most out of available data.\n",
    "  * Separate methods were written to process features. Note that it returns a new column. This is more flexible than operating on the original dataframe.\n",
    "  * _Important_: use dummies to convert multiclass category values to binary numerical classes. As a result, more features are added.\n",
    "  * _Important_: dimension reduction using SelectFromModel. This is a meta selector that would choose a subset of features based on the importance calcuated from a base model.\n",
    "  * Scale of features: for tree based models, it shouldn't matter, but it shouldn't hurt either to use normalized features. Ahmed used max to normalize. My experience is that switching to min_max scaling helps with the result.\n",
    "* Fitting\n",
    "  * Use RandomForest. It is critical to adjust the parameters. It also works without features reduction using SelectFromModel, although slightly worse.\n",
    "  * When using full features, adjusting min_samples_leaf helps. But it doesn't help with reduced feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/yu/MachineLearning/\"))\n",
    "from machine_learning_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Pclass  \\\n",
       "0      0            1       3   \n",
       "1      1            2       1   \n",
       "2      2            3       3   \n",
       "3      3            4       1   \n",
       "4      4            5       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked    set  \n",
       "0      0         A/5 21171   7.2500   NaN        S  train  \n",
       "1      0          PC 17599  71.2833   C85        C  train  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  train  \n",
       "3      0            113803  53.1000  C123        S  train  \n",
       "4      0            373450   8.0500   NaN        S  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the training and test data. combine them together for feature engineering. \n",
    "# * Use the features from test can get the most from the available information\n",
    "# * The test features need to be processed in the same way as training features anyway.\n",
    "train_df = pd.read_csv('train.csv', header=0)\n",
    "train_df['set'] = 'train' # category to indicate training data\n",
    "train_df.drop('Survived', axis=1, inplace=True) # for feature engineering, we don't need the result\n",
    "test_df = pd.read_csv('test.csv', header=0)\n",
    "test_df['set'] = 'test' # category to indicate testing data\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "combined_df.reset_index(inplace=True) # after pd.concat the index is from train_df and test_df and needs to be reset\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      "index          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1046 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "set            1309 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 102.3+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to fill the following\n",
    "* Age\n",
    "* Cabin\n",
    "* Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parse title from name\n",
    "# add titles\n",
    "# a map of more aggregated titles\n",
    "import re\n",
    "def get_title(title):\n",
    "    Title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        \"Don\":        \"Royalty\",\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                        }\n",
    "    match = re.search(',\\s([a-zA-Z\\s]+)\\.', title)\n",
    "    if match:\n",
    "        return Title_Dictionary[match.group(1)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_title(df):\n",
    "    return df['Name'].map(lambda x: get_title(x))\n",
    "    \n",
    "\n",
    "combined_df['Title'] = add_title(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more detailed imputation of age\n",
    "# fill unknown age with median based on other features.\n",
    "\n",
    "def fill_unknown(df, unknown, features):\n",
    "    median_unknown = df.groupby(features).median()[unknown]\n",
    "    # get the median age based on features\n",
    "    for i, r in df.iterrows(): # loop through the rows   \n",
    "        if np.isnan(r[unknown]):\n",
    "            m = median_unknown\n",
    "            for f in features:  # loop through the features to select the median based on all features\n",
    "                m = m[r[f]]\n",
    "            df.loc[i, 'filled'] = m\n",
    "        else:\n",
    "            df.loc[i, 'filled'] = r[unknown]\n",
    "    return df['filled']\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Title']\n",
    "combined_df['AgeFilled'] = fill_unknown(combined_df, 'Age', features)\n",
    "features = ['Pclass']\n",
    "combined_df['FareFilled'] = fill_unknown(combined_df, 'Fare', features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill embark info with the most frequent\n",
    "combined_df['EmbardedFilled'] = combined_df['Embarked'].fillna(combined_df['Embarked'].dropna().mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process cabin. unknown cabin is n. known cabin is coded by the first letter\n",
    "combined_df['CabinFilled'] = combined_df['Cabin'].map(lambda x: str(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert Sex to numerical value\n",
    "combined_df['Sex_n'] = combined_df['Sex'].map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process tickets\n",
    "\n",
    "\n",
    "def add_prefex(df, features):\n",
    "    # extract the alphabetic prefix from features, if not found, use XXX\n",
    "    for f in features:\n",
    "        for (i, r) in df.iterrows():\n",
    "            x = r[f]\n",
    "            x = re.sub('(\\W+)', '', x) # remove any non-alphabetic characters\n",
    "            matched = re.match('([a-zA-Z]+)', x)\n",
    "            if matched:\n",
    "                df.loc[i, f+'_pre'] = matched.group(0)\n",
    "            else:\n",
    "                df.loc[i, f+'_pre'] = 'XXX'\n",
    "    return df[[f+'_pre' for f in features]]\n",
    "\n",
    "combined_df['Ticket_pre'] = add_prefex(combined_df, ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process family size\n",
    "combined_df['FamilySize'] = combined_df['Parch'] + combined_df['SibSp'] + 1\n",
    "combined_df.loc[combined_df.FamilySize == 1, 'FamilyType'] = 'S'\n",
    "combined_df.loc[(combined_df.FamilySize >= 2) & (combined_df.FamilySize <= 4), 'FamilyType'] = 'M'\n",
    "combined_df.loc[(combined_df.FamilySize > 4), 'FamilyType'] = 'L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 23 columns):\n",
      "index             1309 non-null int64\n",
      "PassengerId       1309 non-null int64\n",
      "Pclass            1309 non-null int64\n",
      "Name              1309 non-null object\n",
      "Sex               1309 non-null object\n",
      "Age               1046 non-null float64\n",
      "SibSp             1309 non-null int64\n",
      "Parch             1309 non-null int64\n",
      "Ticket            1309 non-null object\n",
      "Fare              1308 non-null float64\n",
      "Cabin             295 non-null object\n",
      "Embarked          1307 non-null object\n",
      "set               1309 non-null object\n",
      "Title             1309 non-null object\n",
      "filled            1309 non-null float64\n",
      "AgeFilled         1309 non-null float64\n",
      "FareFilled        1309 non-null float64\n",
      "EmbardedFilled    1309 non-null object\n",
      "CabinFilled       1309 non-null object\n",
      "Sex_n             1309 non-null int64\n",
      "Ticket_pre        1309 non-null object\n",
      "FamilySize        1309 non-null int64\n",
      "FamilyType        1309 non-null object\n",
      "dtypes: float64(5), int64(7), object(11)\n",
      "memory usage: 179.0+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert categorical data to a collection of binary data\n",
    "def add_dummies(df, categories):\n",
    "## return columns named category_i\n",
    "    dummies = pd.DataFrame()\n",
    "    for c in categories:\n",
    "        dummies = pd.concat([dummies, pd.get_dummies(df[c], prefix=c)], axis=1)\n",
    "    return dummies\n",
    "\n",
    "combined_df = pd.concat([combined_df, add_dummies(combined_df, ['Title'])], axis=1)\n",
    "combined_df = pd.concat([combined_df, add_dummies(combined_df, \n",
    "                                                  ['EmbardedFilled', 'CabinFilled', 'Pclass', 'Ticket_pre', 'FamilyType'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale all numerical features\n",
    "scaled_df = combined_df.drop('index', axis=1)\n",
    "scaled_df = combined_df.drop('PassengerId', axis=1)\n",
    "features = scaled_df.columns\n",
    "for f in features:\n",
    "    if scaled_df[f].dtypes != object:\n",
    "        scaled_df[f] = scaled_df[f]/scaled_df[f].max()\n",
    "scaled_df = pd.concat([scaled_df, combined_df['PassengerId']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_pre_STONO</th>\n",
       "      <th>Ticket_pre_STONOQ</th>\n",
       "      <th>Ticket_pre_SWPP</th>\n",
       "      <th>Ticket_pre_WC</th>\n",
       "      <th>Ticket_pre_WEP</th>\n",
       "      <th>Ticket_pre_XXX</th>\n",
       "      <th>FamilyType_L</th>\n",
       "      <th>FamilyType_M</th>\n",
       "      <th>FamilyType_S</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                               Name     Sex  \\\n",
       "0  1.000000                            Braund, Mr. Owen Harris    male   \n",
       "1  0.333333  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2  1.000000                             Heikkinen, Miss. Laina  female   \n",
       "3  0.333333       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4  1.000000                           Allen, Mr. William Henry    male   \n",
       "\n",
       "      Age  SibSp  Parch            Ticket      Fare Cabin Embarked  \\\n",
       "0  0.2750  0.125    0.0         A/5 21171  0.014151   NaN        S   \n",
       "1  0.4750  0.125    0.0          PC 17599  0.139136   C85        C   \n",
       "2  0.3250  0.000    0.0  STON/O2. 3101282  0.015469   NaN        S   \n",
       "3  0.4375  0.125    0.0            113803  0.103644  C123        S   \n",
       "4  0.4375  0.000    0.0            373450  0.015713   NaN        S   \n",
       "\n",
       "      ...      Ticket_pre_STONO Ticket_pre_STONOQ  Ticket_pre_SWPP  \\\n",
       "0     ...                   0.0               0.0              0.0   \n",
       "1     ...                   0.0               0.0              0.0   \n",
       "2     ...                   1.0               0.0              0.0   \n",
       "3     ...                   0.0               0.0              0.0   \n",
       "4     ...                   0.0               0.0              0.0   \n",
       "\n",
       "   Ticket_pre_WC  Ticket_pre_WEP Ticket_pre_XXX FamilyType_L  FamilyType_M  \\\n",
       "0            0.0             0.0            0.0          0.0           1.0   \n",
       "1            0.0             0.0            0.0          0.0           1.0   \n",
       "2            0.0             0.0            0.0          0.0           0.0   \n",
       "3            0.0             0.0            1.0          0.0           1.0   \n",
       "4            0.0             0.0            1.0          0.0           0.0   \n",
       "\n",
       "  FamilyType_S  PassengerId  \n",
       "0          0.0            1  \n",
       "1          0.0            2  \n",
       "2          1.0            3  \n",
       "3          0.0            4  \n",
       "4          1.0            5  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df.drop('index', axis=1, inplace=True)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is essentially copied from Ahmed's post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def compute_score(clf, X, y,scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5,scoring=scoring)\n",
    "    return np.mean(xval)\n",
    "\n",
    "def recover_train_test_target(df):\n",
    "    train0 = pd.read_csv('train.csv')\n",
    "    targets = train0.Survived\n",
    "    train = df.ix[0:890]\n",
    "    test = df.ix[891:]\n",
    "    \n",
    "    return train,test,targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_df.drop(['Name', 'Sex', 'Age', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'set', 'Title', 'filled', \n",
    "        'EmbardedFilled', 'CabinFilled', 'Ticket_pre', 'Pclass', 'FamilyType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,test,targets = recover_train_test_target(scaled_df)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf = clf.fit(train, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.128301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgeFilled</td>\n",
       "      <td>0.119741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FareFilled</td>\n",
       "      <td>0.114454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex_n</td>\n",
       "      <td>0.107414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.103413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.042085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.039438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.038916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CabinFilled_n</td>\n",
       "      <td>0.028687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.022119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>FamilyType_M</td>\n",
       "      <td>0.021292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>FamilyType_L</td>\n",
       "      <td>0.017376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.016772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.015161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.013855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EmbardedFilled_S</td>\n",
       "      <td>0.012764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Ticket_pre_XXX</td>\n",
       "      <td>0.012305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>FamilyType_S</td>\n",
       "      <td>0.011317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EmbardedFilled_C</td>\n",
       "      <td>0.010515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CabinFilled_E</td>\n",
       "      <td>0.009813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EmbardedFilled_Q</td>\n",
       "      <td>0.007406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Title_Officer</td>\n",
       "      <td>0.006940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CabinFilled_B</td>\n",
       "      <td>0.006722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CabinFilled_D</td>\n",
       "      <td>0.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ticket_pre_STONO</td>\n",
       "      <td>0.006381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CabinFilled_C</td>\n",
       "      <td>0.006240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ticket_pre_SWPP</td>\n",
       "      <td>0.006217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ticket_pre_PC</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ticket_pre_C</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ticket_pre_SOTONOQ</td>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ticket_pre_SOPP</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CabinFilled_F</td>\n",
       "      <td>0.001595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CabinFilled_G</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Title_Royalty</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ticket_pre_PP</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ticket_pre_WEP</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ticket_pre_LINE</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ticket_pre_FC</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ticket_pre_SOC</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ticket_pre_SCPARIS</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ticket_pre_FCC</td>\n",
       "      <td>0.000523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ticket_pre_SCParis</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CabinFilled_T</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ticket_pre_SOP</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ticket_pre_SCAH</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ticket_pre_SC</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ticket_pre_SP</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ticket_pre_PPP</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ticket_pre_SCAHBasle</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ticket_pre_SOTONO</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ticket_pre_SCOW</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ticket_pre_SCA</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ticket_pre_Fa</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ticket_pre_AS</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ticket_pre_CASOTON</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ticket_pre_AQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ticket_pre_STONOQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ticket_pre_LP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance\n",
       "63           PassengerId    0.128301\n",
       "2              AgeFilled    0.119741\n",
       "3             FareFilled    0.114454\n",
       "4                  Sex_n    0.107414\n",
       "8               Title_Mr    0.103413\n",
       "7             Title_Miss    0.042085\n",
       "26              Pclass_3    0.039438\n",
       "9              Title_Mrs    0.038916\n",
       "23         CabinFilled_n    0.028687\n",
       "24              Pclass_1    0.022119\n",
       "61          FamilyType_M    0.021292\n",
       "5             FamilySize    0.020467\n",
       "60          FamilyType_L    0.017376\n",
       "0                  SibSp    0.016772\n",
       "1                  Parch    0.015161\n",
       "25              Pclass_2    0.013855\n",
       "6           Title_Master    0.012834\n",
       "14      EmbardedFilled_S    0.012764\n",
       "59        Ticket_pre_XXX    0.012305\n",
       "62          FamilyType_S    0.011317\n",
       "12      EmbardedFilled_C    0.010515\n",
       "19         CabinFilled_E    0.009813\n",
       "13      EmbardedFilled_Q    0.007406\n",
       "10         Title_Officer    0.006940\n",
       "16         CabinFilled_B    0.006722\n",
       "18         CabinFilled_D    0.006623\n",
       "54      Ticket_pre_STONO    0.006381\n",
       "17         CabinFilled_C    0.006240\n",
       "56       Ticket_pre_SWPP    0.006217\n",
       "38         Ticket_pre_PC    0.006114\n",
       "..                   ...         ...\n",
       "30          Ticket_pre_C    0.001949\n",
       "52    Ticket_pre_SOTONOQ    0.001837\n",
       "50       Ticket_pre_SOPP    0.001699\n",
       "20         CabinFilled_F    0.001595\n",
       "21         CabinFilled_G    0.001345\n",
       "11         Title_Royalty    0.001312\n",
       "39         Ticket_pre_PP    0.000925\n",
       "58        Ticket_pre_WEP    0.000754\n",
       "36       Ticket_pre_LINE    0.000730\n",
       "33         Ticket_pre_FC    0.000675\n",
       "48        Ticket_pre_SOC    0.000623\n",
       "46    Ticket_pre_SCPARIS    0.000573\n",
       "34        Ticket_pre_FCC    0.000523\n",
       "47    Ticket_pre_SCParis    0.000444\n",
       "22         CabinFilled_T    0.000342\n",
       "49        Ticket_pre_SOP    0.000195\n",
       "43       Ticket_pre_SCAH    0.000180\n",
       "41         Ticket_pre_SC    0.000143\n",
       "53         Ticket_pre_SP    0.000134\n",
       "40        Ticket_pre_PPP    0.000074\n",
       "44  Ticket_pre_SCAHBasle    0.000060\n",
       "51     Ticket_pre_SOTONO    0.000059\n",
       "45       Ticket_pre_SCOW    0.000057\n",
       "42        Ticket_pre_SCA    0.000055\n",
       "35         Ticket_pre_Fa    0.000043\n",
       "29         Ticket_pre_AS    0.000039\n",
       "32    Ticket_pre_CASOTON    0.000028\n",
       "28         Ticket_pre_AQ    0.000000\n",
       "55     Ticket_pre_STONOQ    0.000000\n",
       "37         Ticket_pre_LP    0.000000\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_new = model.transform(train)\n",
    "train_new.shape\n",
    "test_new = model.transform(test)\n",
    "test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.832772166105\n",
      "Best parameters: {'n_estimators': 250, 'criterion': 'gini', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,210,240,250],\n",
    "                 'criterion': ['gini','entropy']\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train_new, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = grid_search.predict(test_new).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.79426. An improvement over my earlier by about 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Learn about SelectFromModel\n",
    "* Try to write some utility methods\n",
    "* Modify some obvious weak points (such as the scaling of Fare)\n",
    "* Try to figure our which step is more important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel\n",
    "Based on the importance field of an estimator, features are selected. In the script from Ahmed, SelectFromModel takes an already fitted ExtraTreeClassifer as input. It can also take a classifier and fit it as part of the invocation of SelectFromModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale all numerical features by min_max (step 1/3)\n",
    "minmaxscaled_df = combined_df.drop('index', axis=1)\n",
    "minmaxscaled_df = combined_df.drop('PassengerId', axis=1)\n",
    "features = minmaxscaled_df.columns\n",
    "for f in features:\n",
    "    if minmaxscaled_df[f].dtypes != object:\n",
    "        minmaxscaled_df[f] = (minmaxscaled_df[f]-minmaxscaled_df[f].min())/(minmaxscaled_df[f].max()\n",
    "                                                                            -minmaxscaled_df[f].min())\n",
    "minmaxscaled_df = pd.concat([minmaxscaled_df, combined_df['PassengerId']], axis=1)\n",
    "minmaxscaled_df.drop('index', axis=1, inplace=True)\n",
    "minmaxscaled_df.drop(['Name', 'Sex', 'Age', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'set', 'Title', 'filled', \n",
    "        'EmbardedFilled', 'CabinFilled', 'Ticket_pre', 'Pclass', 'FamilyType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features (step 2/3)\n",
    "train,test,targets = recover_train_test_target(minmaxscaled_df)\n",
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf = clf.fit(train, targets)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_new = model.transform(train)\n",
    "train_new.shape\n",
    "test_new = model.transform(test)\n",
    "test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.83164983165\n",
      "Best parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# fit with random forest (step 3/3)\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [300],\n",
    "                 'criterion': ['gini','entropy']\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train_new, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "output = grid_search.predict(test_new).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.80861, better than the orignal method by Ahmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.83164983165\n",
      "Best parameters: {'n_estimators': 180, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "# fit with random forest with min_samples_leaf(step 3/3)\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [160,180,200,210],\n",
    "                 'criterion': ['gini'],\n",
    "                 'min_samples_leaf': [10, 20, 30, 40]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train_new, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "output = grid_search.predict(test_new).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.78469, not as good as above. Why min_samples_leaf doesn't make it better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about using minmaxscaled directly without feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.832772166105\n",
      "Best parameters: {'n_estimators': 210, 'criterion': 'gini', 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# attemp 1: fit with random forest (step 1/1)\n",
    "train,test,targets = recover_train_test_target(minmaxscaled_df)\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,210,240,250],\n",
    "                 'criterion': ['gini','entropy']\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "output = grid_search.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.78947, better than the score before using Ahmed's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.828282828283\n",
      "Best parameters: {'n_estimators': 200, 'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "# attempt 2: fit with random forest (step 1/1), adjust min_samples_leaf\n",
    "train,test,targets = recover_train_test_target(minmaxscaled_df)\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,210,240,250],\n",
    "                 'criterion': ['gini'],\n",
    "                 'min_samples_leaf': [10, 20, 30, 40]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "output = grid_search.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.79426, better than the score before using Ahmed's method. This is also better than attempt 1.\n",
    "# Does it mean that it could be used to improve Ahmed's method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.812570145903\n",
      "Best parameters: {'n_estimators': 210, 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# attempt 3: fit with random forest (step 1/1), fix min_samples_leaf\n",
    "train,test,targets = recover_train_test_target(minmaxscaled_df)\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,210,240,250],\n",
    "                 'criterion': ['gini'],\n",
    "                 'min_samples_leaf': [30]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train, targets)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "output = grid_search.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "df_output['PassengerId'] = test['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('ahmed.csv',index=False)\n",
    "# leader board: 0.78947. Not as good as attempt 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful references\n",
    "* How to tune randome forest (https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/)\n",
    "  * n_estimator: the higher the better, but takes longer to train\n",
    "  * min_samples_leaf: avoid overfitting\n",
    "  * max_features:\n",
    "* A detailed tutorial to achieve 0.81 on leader board (http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)\n",
    "  * Use stratified kfold\n",
    "  * Use ExtraTreesClassifier + SelectFromModel to reduce dimensionality\n",
    "  * How to convert multiclass features to multifeatures of binary class. use dummies.\n",
    "  * Proper normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
